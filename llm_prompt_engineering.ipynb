{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8c9RaQYH/197tAa9p+ZI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pronow05/NL2SQL-LangChain/blob/main/llm_prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Postgresql DB Setup"
      ],
      "metadata": {
        "id": "ig0R1oLhLIAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mr9TI8uZJ7B0",
        "outputId": "9b8dcbce-1aef-48d4-ac81-c8fd730c712d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,312 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,655 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,609 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,673 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.0 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,612 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,911 kB]\n",
            "Fetched 23.7 MB in 3s (7,779 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y postgresql postgresql-contrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IWi0Y5xHKdO-",
        "outputId": "7dd7a9cd-d7e4-4891-9b33-30d477cb8e90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl logrotate netbase\n",
            "  postgresql-14 postgresql-client-14 postgresql-client-common postgresql-common ssl-cert sysstat\n",
            "Suggested packages:\n",
            "  bsd-mailx | mailx postgresql-doc postgresql-doc-14 isag\n",
            "The following NEW packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl logrotate netbase\n",
            "  postgresql postgresql-14 postgresql-client-14 postgresql-client-common postgresql-common\n",
            "  postgresql-contrib ssl-cert sysstat\n",
            "0 upgraded, 14 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 18.4 MB of archives.\n",
            "After this operation, 51.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 logrotate amd64 3.19.0-1ubuntu1.1 [54.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcommon-sense-perl amd64 3.75-2build1 [21.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-perl all 4.04000-1 [81.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtypes-serialiser-perl all 1.01-1 [11.6 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-xs-perl amd64 4.030-1build3 [87.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-client-common all 238 [29.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 postgresql-client-14 amd64 14.15-0ubuntu0.22.04.1 [1,225 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 ssl-cert all 1.1.2 [17.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-common all 238 [169 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 postgresql-14 amd64 14.15-0ubuntu0.22.04.1 [16.2 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql all 14+238 [3,288 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-contrib all 14+238 [3,292 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]\n",
            "Fetched 18.4 MB in 1s (15.1 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package logrotate.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-logrotate_3.19.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../01-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package libcommon-sense-perl:amd64.\n",
            "Preparing to unpack .../02-libcommon-sense-perl_3.75-2build1_amd64.deb ...\n",
            "Unpacking libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Selecting previously unselected package libjson-perl.\n",
            "Preparing to unpack .../03-libjson-perl_4.04000-1_all.deb ...\n",
            "Unpacking libjson-perl (4.04000-1) ...\n",
            "Selecting previously unselected package libtypes-serialiser-perl.\n",
            "Preparing to unpack .../04-libtypes-serialiser-perl_1.01-1_all.deb ...\n",
            "Unpacking libtypes-serialiser-perl (1.01-1) ...\n",
            "Selecting previously unselected package libjson-xs-perl.\n",
            "Preparing to unpack .../05-libjson-xs-perl_4.030-1build3_amd64.deb ...\n",
            "Unpacking libjson-xs-perl (4.030-1build3) ...\n",
            "Selecting previously unselected package postgresql-client-common.\n",
            "Preparing to unpack .../06-postgresql-client-common_238_all.deb ...\n",
            "Unpacking postgresql-client-common (238) ...\n",
            "Selecting previously unselected package postgresql-client-14.\n",
            "Preparing to unpack .../07-postgresql-client-14_14.15-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-client-14 (14.15-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package ssl-cert.\n",
            "Preparing to unpack .../08-ssl-cert_1.1.2_all.deb ...\n",
            "Unpacking ssl-cert (1.1.2) ...\n",
            "Selecting previously unselected package postgresql-common.\n",
            "Preparing to unpack .../09-postgresql-common_238_all.deb ...\n",
            "Adding 'diversion of /usr/bin/pg_config to /usr/bin/pg_config.libpq-dev by postgresql-common'\n",
            "Unpacking postgresql-common (238) ...\n",
            "Selecting previously unselected package postgresql-14.\n",
            "Preparing to unpack .../10-postgresql-14_14.15-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-14 (14.15-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package postgresql.\n",
            "Preparing to unpack .../11-postgresql_14+238_all.deb ...\n",
            "Unpacking postgresql (14+238) ...\n",
            "Selecting previously unselected package postgresql-contrib.\n",
            "Preparing to unpack .../12-postgresql-contrib_14+238_all.deb ...\n",
            "Unpacking postgresql-contrib (14+238) ...\n",
            "Selecting previously unselected package sysstat.\n",
            "Preparing to unpack .../13-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking sysstat (12.5.2-2ubuntu0.2) ...\n",
            "Setting up logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Created symlink /etc/systemd/system/timers.target.wants/logrotate.timer ‚Üí /lib/systemd/system/logrotate.timer.\n",
            "Setting up libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Setting up ssl-cert (1.1.2) ...\n",
            "Setting up libtypes-serialiser-perl (1.01-1) ...\n",
            "Setting up libjson-perl (4.04000-1) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up sysstat (12.5.2-2ubuntu0.2) ...\n",
            "\n",
            "Creating config file /etc/default/sysstat with new version\n",
            "update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer ‚Üí /lib/systemd/system/sysstat-collect.timer.\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer ‚Üí /lib/systemd/system/sysstat-summary.timer.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service ‚Üí /lib/systemd/system/sysstat.service.\n",
            "Setting up postgresql-client-common (238) ...\n",
            "Setting up libjson-xs-perl (4.030-1build3) ...\n",
            "Setting up postgresql-client-14 (14.15-0ubuntu0.22.04.1) ...\n",
            "update-alternatives: using /usr/share/postgresql/14/man/man1/psql.1.gz to provide /usr/share/man/man1/psql.1.gz (psql.1.gz) in auto mode\n",
            "Setting up postgresql-common (238) ...\n",
            "Adding user postgres to group ssl-cert\n",
            "\n",
            "Creating config file /etc/postgresql-common/createcluster.conf with new version\n",
            "Building PostgreSQL dictionaries from installed myspell/hunspell packages...\n",
            "Removing obsolete dictionary files:\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service ‚Üí /lib/systemd/system/postgresql.service.\n",
            "Setting up postgresql-14 (14.15-0ubuntu0.22.04.1) ...\n",
            "Creating new PostgreSQL cluster 14/main ...\n",
            "/usr/lib/postgresql/14/bin/initdb -D /var/lib/postgresql/14/main --auth-local peer --auth-host scram-sha-256 --no-instructions\n",
            "The files belonging to this database system will be owned by user \"postgres\".\n",
            "This user must also own the server process.\n",
            "\n",
            "The database cluster will be initialized with locale \"en_US.UTF-8\".\n",
            "The default database encoding has accordingly been set to \"UTF8\".\n",
            "The default text search configuration will be set to \"english\".\n",
            "\n",
            "Data page checksums are disabled.\n",
            "\n",
            "fixing permissions on existing directory /var/lib/postgresql/14/main ... ok\n",
            "creating subdirectories ... ok\n",
            "selecting dynamic shared memory implementation ... posix\n",
            "selecting default max_connections ... 100\n",
            "selecting default shared_buffers ... 128MB\n",
            "selecting default time zone ... Etc/UTC\n",
            "creating configuration files ... ok\n",
            "running bootstrap script ... ok\n",
            "performing post-bootstrap initialization ... ok\n",
            "syncing data to disk ... ok\n",
            "update-alternatives: using /usr/share/postgresql/14/man/man1/postmaster.1.gz to provide /usr/share/man/man1/postmaster.1.gz (postmaster.1.gz) in auto mode\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up postgresql-contrib (14+238) ...\n",
            "Setting up postgresql (14+238) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!service postgresql start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_tNdjslKj93",
        "outputId": "7d60fc2b-706f-45f4-dd97-ee10d8a07d01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD '006563';\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LtWEbt9Kj6c",
        "outputId": "59c874cf-7e40-43c1-b571-dc2c19b319f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALTER ROLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo -u postgres psql -c \"CREATE DATABASE airbnb;\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og5Y2IoGKj4C",
        "outputId": "b38dffa0-84c3-410c-a382-4be70312fe7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATE DATABASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psycopg2-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sfpYxgyKj1v",
        "outputId": "f0787ed3-cde2-49ed-9bff-ea955e4d06aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.5/3.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining DB Schema"
      ],
      "metadata": {
        "id": "6YbYi5ljLARY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "\n",
        "# Connect to PostgreSQL\n",
        "conn = psycopg2.connect(\n",
        "    dbname=\"airbnb\",\n",
        "    user=\"postgres\",\n",
        "    password=\"006563\",\n",
        "    host=\"localhost\"\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Check connection\n",
        "cursor.execute(\"SELECT version();\")\n",
        "print(cursor.fetchone())\n",
        "\n",
        "# Close cursor and connection\n",
        "cursor.close()\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86DWXL8pKjzg",
        "outputId": "02fd5db4-4940-4d4f-cc02-a51b36fc2a2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('PostgreSQL 14.15 (Ubuntu 14.15-0ubuntu0.22.04.1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, 64-bit',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = psycopg2.connect(\n",
        "    dbname=\"airbnb\",\n",
        "    user=\"postgres\",\n",
        "    password=\"006563\",\n",
        "    host=\"localhost\"\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create Listings Table\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE listings (\n",
        "    listing_id SERIAL PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    host_id INTEGER,\n",
        "    host_since DATE,\n",
        "    host_location TEXT,\n",
        "    host_response_time TEXT,\n",
        "    host_response_rate TEXT,\n",
        "    host_acceptance_rate TEXT,\n",
        "    host_is_superhost BOOLEAN,\n",
        "    host_total_listings_count INTEGER,\n",
        "    host_has_profile_pic BOOLEAN,\n",
        "    host_identity_verified BOOLEAN,\n",
        "    neighbourhood TEXT,\n",
        "    district TEXT,\n",
        "    city TEXT,\n",
        "    latitude DECIMAL(9,6),\n",
        "    longitude DECIMAL(9,6),\n",
        "    property_type TEXT,\n",
        "    room_type TEXT,\n",
        "    accommodates INTEGER,\n",
        "    bedrooms INTEGER,\n",
        "    amenities TEXT,\n",
        "    price DECIMAL(10,2),\n",
        "    minimum_nights INTEGER,\n",
        "    maximum_nights INTEGER,\n",
        "    review_scores_rating FLOAT,\n",
        "    review_scores_accuracy FLOAT,\n",
        "    review_scores_cleanliness FLOAT,\n",
        "    review_scores_checkin FLOAT,\n",
        "    review_scores_communication FLOAT,\n",
        "    review_scores_location FLOAT,\n",
        "    review_scores_value FLOAT,\n",
        "    instant_bookable BOOLEAN\n",
        ");\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# Create Reviews Table\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE reviews (\n",
        "    review_id SERIAL PRIMARY KEY,\n",
        "    listing_id INTEGER REFERENCES listings(listing_id),\n",
        "    date DATE,\n",
        "    reviewer_id INTEGER\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "QmtBrZiOKjw_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Import to Table from CSV"
      ],
      "metadata": {
        "id": "_dptKNyqMk46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Data from Listings.csv to listings table using psql COPY command**"
      ],
      "metadata": {
        "id": "lhpZrNddM6UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo -u postgres psql -d airbnb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3gJmoQUKjuz",
        "outputId": "445a0413-e399-4481-c13d-1a74a556377f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "psql (14.15 (Ubuntu 14.15-0ubuntu0.22.04.1))\n",
            "Type \"help\" for help.\n",
            "\n",
            "\u001b[?2004hairbnb=# COPY listings(     listing_id, name, host_id, host_since, host_location,     host_response_time, host_response_rate, host_acceptance_rate,     host_is_superhost, host_total_listings_count, host_has_profile_pic,     host_identity_verified, neighbourhood, district, city, latitude,     longitude, property_type, room_type, accommodates, bedrooms,     amenities, price, minimum_nights, maximum_nights, review_scores_rating,     review_scores_accuracy, review_scores_cleanliness, review_scores_checkin,     review_scores_communication, review_scores_location, review_scores_value,     instant_bookable ) FROM '/content/Listings.csv' WITH (FORMAT csv, HEADER true, ENCODING 'LATIN1');\n",
            "COPY 279712\n",
            "\u001b[?2004hairbnb=# \\q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning Reviews.csv and then importing into reviews Table**"
      ],
      "metadata": {
        "id": "rHmp_0OdNQoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_reviews = pd.read_csv(\"Reviews.csv\", encoding=\"latin1\")\n",
        "df_reviews_clean = df_reviews.drop_duplicates(subset=['review_id'])\n",
        "df_reviews_clean.to_csv(\"Reviews_clean.csv\", index=False)"
      ],
      "metadata": {
        "id": "2tz15MNfKjsR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo -u postgres psql -d airbnb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2Vmo18dKjp0",
        "outputId": "da82679e-e36b-4b39-d959-a345e94b210c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "psql (14.15 (Ubuntu 14.15-0ubuntu0.22.04.1))\n",
            "Type \"help\" for help.\n",
            "\n",
            "\u001b[?2004hairbnb=# COPY reviews(listing_id, review_id, date, reviewer_id) FROM '/content/Reviews_clean.csv' WITH (FORMAT csv, HEADER true, ENCODING 'LATIN1');\n",
            "COPY 5372983\n",
            "\u001b[?2004hairbnb=# \\q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify Succesful Importing of Data**"
      ],
      "metadata": {
        "id": "6PflBw2LN8Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn = psycopg2.connect(\n",
        "    dbname=\"airbnb\",\n",
        "    user=\"postgres\",\n",
        "    password=\"006563\",\n",
        "    host=\"localhost\"\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT * FROM listings LIMIT 5;\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "cursor.execute(\"SELECT * FROM reviews LIMIT 5;\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "cursor.close()\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2bckDEQKjnQ",
        "outputId": "7c077bbb-5ef4-4095-a949-9c82e02f307c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(281420, 'Beautiful Flat in le Village Montmartre, Paris', 1466919, datetime.date(2011, 12, 3), 'Paris, Ile-de-France, France', None, None, None, False, 1, True, False, 'Buttes-Montmartre', None, 'Paris', Decimal('48.886680'), Decimal('2.333430'), 'Entire apartment', 'Entire place', 2, 1, '[\"Heating\", \"Kitchen\", \"Washer\", \"Wifi\", \"Long term stays allowed\"]', Decimal('53.00'), 2, 1125, 100.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, False), (3705183, '39 m√É\\x82√Ç¬≤ Paris (Sacre C√É\\x85√¢\\x80\\x9cur)', 10328771, datetime.date(2013, 11, 29), 'Paris, Ile-de-France, France', None, None, None, False, 1, True, True, 'Buttes-Montmartre', None, 'Paris', Decimal('48.886170'), Decimal('2.345150'), 'Entire apartment', 'Entire place', 2, 1, '[\"Shampoo\", \"Heating\", \"Kitchen\", \"Essentials\", \"Washer\", \"Dryer\", \"Wifi\", \"Long term stays allowed\"]', Decimal('120.00'), 2, 1125, 100.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, False), (4082273, 'Lovely apartment with Terrace, 60m2', 19252768, datetime.date(2014, 7, 31), 'Paris, Ile-de-France, France', None, None, None, False, 1, True, False, 'Elysee', None, 'Paris', Decimal('48.881120'), Decimal('2.317120'), 'Entire apartment', 'Entire place', 2, 1, '[\"Heating\", \"TV\", \"Kitchen\", \"Washer\", \"Wifi\", \"Long term stays allowed\"]', Decimal('89.00'), 2, 1125, 100.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, False), (4797344, 'Cosy studio (close to Eiffel tower)', 10668311, datetime.date(2013, 12, 17), 'Paris, Ile-de-France, France', None, None, None, False, 1, True, True, 'Vaugirard', None, 'Paris', Decimal('48.845710'), Decimal('2.305840'), 'Entire apartment', 'Entire place', 2, 1, '[\"Heating\", \"TV\", \"Kitchen\", \"Wifi\", \"Long term stays allowed\"]', Decimal('58.00'), 2, 1125, 100.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, False), (4823489, 'Close to Eiffel Tower - Beautiful flat : 2 rooms', 24837558, datetime.date(2014, 12, 14), 'Paris, Ile-de-France, France', None, None, None, False, 1, True, False, 'Passy', None, 'Paris', Decimal('48.855000'), Decimal('2.269790'), 'Entire apartment', 'Entire place', 2, 1, '[\"Heating\", \"TV\", \"Kitchen\", \"Essentials\", \"Hair dryer\", \"Washer\", \"Dryer\", \"Bathtub\", \"Wifi\", \"Elevator\", \"Long term stays allowed\", \"Cable TV\"]', Decimal('60.00'), 2, 1125, 100.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, False)]\n",
            "[(330265172, 11798, datetime.date(2018, 9, 30), 11863072), (330103585, 15383, datetime.date(2018, 9, 30), 39147453), (329985788, 16455, datetime.date(2018, 9, 30), 1125378), (330016899, 17919, datetime.date(2018, 9, 30), 172717984), (329995638, 26827, datetime.date(2018, 9, 30), 17542859)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Hugging Face for NL-SQL Conversion"
      ],
      "metadata": {
        "id": "nfOMuLI8OQq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "import torch\n",
        "\n",
        "hf_token = \"hf_EUGYZywXLymYWRpLVKtbClxEhUmkUgUkI\"\n",
        "# Set your model ID (you can change this to your chosen model)\n",
        "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "\n",
        "# Create a Hugging Face text-to-text generation pipeline\n",
        "pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        "    max_length=256,\n",
        "    token=hf_token\n",
        ")\n",
        "\n",
        "# Wrap the pipeline with LangChain‚Äôs HuggingFacePipeline LLM\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "qRC6wrwiPOW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Groq API instead of Hugging Face due limited Computational Resourses**"
      ],
      "metadata": {
        "id": "5vc3yZZuOpO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ofv0K3Kjkp",
        "outputId": "ebc1bf44-da42-4b79-ad2c-8046663d5af5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.33)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.3.6)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.3.0)\n",
            "Downloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.18.0 langchain-groq-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "mNtPYYc3KjiP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize the Groq LLM with the specified model\n",
        "llm = ChatGroq(\n",
        "    model_name=\"llama-3.2-3b-preview\",\n",
        "    temperature=0.3\n",
        ")"
      ],
      "metadata": {
        "id": "JeTkWbwRKjf2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Leveraging LangChain for Prompting"
      ],
      "metadata": {
        "id": "Bxszpa0bPt7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "ga9IQ8WVPwrz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero Shot Prompt Template"
      ],
      "metadata": {
        "id": "TExT3GM6QdyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=\"\"\"\n",
        "    You are an expert SQL generator.\n",
        "\n",
        "    Given the following database schema with comments:\n",
        "    {schema}\n",
        "\n",
        "    Generate a **syntactically correct** SQL query for the following question:\n",
        "    **Question:** {question}\n",
        "\n",
        "    **Rules:**\n",
        "    - Ensure the query aligns with the schema.\n",
        "    - Use appropriate SQL functions and joins as needed.\n",
        "    - Return only the SQL query.\n",
        "\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZXmaWeH8PwoP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few Shot Prompt Template"
      ],
      "metadata": {
        "id": "jjk-IjY2R_hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=\"\"\"\n",
        "    You are an expert SQL generator.\n",
        "\n",
        "    Given the following database schema with comments:\n",
        "    {schema}\n",
        "\n",
        "    Here are examples of correct SQL queries based on similar questions:\n",
        "\n",
        "    **Example 1:**\n",
        "    **Question:** \"What is the total number of reviews for each listing?\"\n",
        "    **SQL:**\n",
        "    ```\n",
        "    SELECT listing_id, COUNT(review_id) AS total_reviews\n",
        "    FROM reviews\n",
        "    GROUP BY listing_id;\n",
        "    ```\n",
        "\n",
        "    **Example 2:**\n",
        "    **Question:** \"Find the average review score rating for each listing.\"\n",
        "    **SQL:**\n",
        "    ```\n",
        "    SELECT listing_id, AVG(review_scores_rating) AS avg_rating\n",
        "    FROM listings\n",
        "    GROUP BY listing_id;\n",
        "    ```\n",
        "\n",
        "    **Example 3:**\n",
        "    **Question:** \"Get the number of listings hosted by each host.\"\n",
        "    **SQL:**\n",
        "    ```\n",
        "    SELECT host_id, COUNT(listing_id) AS total_listings\n",
        "    FROM listings\n",
        "    GROUP BY host_id;\n",
        "    ```\n",
        "\n",
        "    **Example 4:**\n",
        "    **Question:** \"Retrieve the latest review date for each listing.\"\n",
        "    **SQL:**\n",
        "    ```\n",
        "    SELECT listing_id, MAX(date) AS latest_review_date\n",
        "    FROM reviews\n",
        "    GROUP BY listing_id;\n",
        "    ```\n",
        "\n",
        "    Now, generate a SQL query for the following question:\n",
        "    **Question:** {question}\n",
        "\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZX2DHBbQPwmK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain-Of-Thought Prompt Template"
      ],
      "metadata": {
        "id": "hz7vqlzFSeCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=\"\"\"\n",
        "    You are an expert SQL generator. Before writing the SQL query, think step-by-step.\n",
        "\n",
        "    Given the following database schema with comments:\n",
        "    {schema}\n",
        "\n",
        "    **Question:** {question}\n",
        "\n",
        "    ### **Step 1: Understanding the Request**\n",
        "    - Identify the key entities involved in the query.\n",
        "    - Determine the relationships between tables.\n",
        "    - Identify necessary SQL operations (JOIN, GROUP BY, COUNT, etc.).\n",
        "\n",
        "    ### **Step 2: Breaking Down the Query Construction**\n",
        "    - Identify the base table to query from.\n",
        "    - Determine which columns should be selected.\n",
        "    - Identify necessary filtering, aggregation, or sorting conditions.\n",
        "\n",
        "    ### **Step 3: Constructing the SQL Query**\n",
        "    - Use the above reasoning to generate the correct SQL statement.\n",
        "\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "8Yw7vCQtPJty"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-Consistency Prompt Template"
      ],
      "metadata": {
        "id": "ZLEztwyUTC9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self_consistency_prompt = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=\"\"\"\n",
        "    You are an expert SQL generator.\n",
        "\n",
        "    Given the following database schema with comments:\n",
        "    {schema}\n",
        "\n",
        "    Generate **three different candidate SQL queries** for the following question:\n",
        "    **Question:** {question}\n",
        "\n",
        "    **Candidate 1:**\n",
        "    SQL Query:\n",
        "\n",
        "    **Candidate 2:**\n",
        "    SQL Query:\n",
        "\n",
        "    **Candidate 3:**\n",
        "    SQL Query:\n",
        "\n",
        "    Now, analyze the three queries and select the best one based on correctness and efficiency.\n",
        "\n",
        "    **Final Selected SQL Query:**\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "abtYsbEkTDoZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "JLGeKgfDTEhJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate SQL using a specified prompt template\n",
        "def generate_sql(question, schema, prompt_template):\n",
        "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "    return chain.run({\"schema\": schema, \"question\": question})"
      ],
      "metadata": {
        "id": "0cH74Bn4TEMV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema_description = \"\"\"\n",
        "-- Database Schema for Airbnb Data\n",
        "\n",
        "-- Table: listings\n",
        "-- Description: Contains detailed information about each Airbnb listing.\n",
        "-- Columns:\n",
        "--   listing_id (BIGINT): Unique identifier for each listing.\n",
        "--   name (TEXT): Title or name of the listing.\n",
        "--   host_id (BIGINT): Unique identifier for the host of the listing.\n",
        "--   host_since (DATE): Date when the host began hosting.\n",
        "--   host_location (TEXT): Geographic location of the host.\n",
        "--   host_response_time (TEXT): Typical response time by the host.\n",
        "--   host_response_rate (TEXT): Host‚Äôs response rate (expressed as a percentage in text format).\n",
        "--   host_acceptance_rate (TEXT): Host‚Äôs acceptance rate (expressed as a percentage in text format).\n",
        "--   host_is_superhost (BOOLEAN): Indicates if the host is a superhost (true/false).\n",
        "--   host_total_listings_count (BIGINT): Total number of listings managed by the host.\n",
        "--   host_has_profile_pic (BOOLEAN): Indicates whether the host has a profile picture.\n",
        "--   host_identity_verified (BOOLEAN): Indicates whether the host‚Äôs identity is verified.\n",
        "--   neighbourhood (TEXT): Neighbourhood where the listing is located.\n",
        "--   district (TEXT): District in which the listing is located.\n",
        "--   city (TEXT): City where the listing is located.\n",
        "--   latitude (DECIMAL): Latitude coordinate of the listing.\n",
        "--   longitude (DECIMAL): Longitude coordinate of the listing.\n",
        "--   property_type (TEXT): Type of property (e.g., apartment, house, etc.).\n",
        "--   room_type (TEXT): Type of room offered (e.g., entire home, private room, shared room).\n",
        "--   accommodates (INTEGER): Maximum number of guests the listing can accommodate.\n",
        "--   bedrooms (INTEGER): Number of bedrooms in the listing.\n",
        "--   amenities (TEXT): Comma-separated list of amenities provided.\n",
        "--   price (DECIMAL): Price per night.\n",
        "--   minimum_nights (INTEGER): Minimum number of nights required for booking.\n",
        "--   maximum_nights (INTEGER): Maximum number of nights allowed for booking.\n",
        "--   review_scores_rating (FLOAT): Overall rating score.\n",
        "--   review_scores_accuracy (FLOAT): Accuracy rating score.\n",
        "--   review_scores_cleanliness (FLOAT): Cleanliness rating score.\n",
        "--   review_scores_checkin (FLOAT): Check-in rating score.\n",
        "--   review_scores_communication (FLOAT): Communication rating score.\n",
        "--   review_scores_location (FLOAT): Location rating score.\n",
        "--   review_scores_value (FLOAT): Value for money rating score.\n",
        "--   instant_bookable (BOOLEAN): Indicates whether the listing supports instant booking.\n",
        "\n",
        "-- Table: reviews\n",
        "-- Description: Contains reviews submitted for listings.\n",
        "-- Columns:\n",
        "--   review_id (SERIAL PRIMARY KEY): Unique identifier for each review.\n",
        "--   listing_id (INTEGER): Foreign key linking to listings(listing_id), representing which listing was reviewed.\n",
        "--   date (DATE): Date when the review was posted.\n",
        "--   reviewer_id (INTEGER): Unique identifier for the reviewer.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aEP_yRtCWnde"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Query**"
      ],
      "metadata": {
        "id": "y6RAzthYbZf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let the user input their natural language query\n",
        "user_query = input(\"Enter your natural language SQL query: \")\n",
        "\n",
        "# Generate SQL using different prompting techniques\n",
        "print(\"üîπ Zero-Shot Output:\")\n",
        "print(generate_sql(user_query, schema_description, zero_shot_prompt))\n",
        "\n",
        "print(\"\\nüîπ Few-Shot Output:\")\n",
        "print(generate_sql(user_query, schema_description, few_shot_prompt))\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Output:\")\n",
        "print(generate_sql(user_query, schema_description, cot_prompt))\n",
        "\n",
        "print(\"\\nüîπ Self-Consistency Output:\")\n",
        "print(generate_sql(user_query, schema_description, self_consistency_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGREGf1CW4a3",
        "outputId": "08066f18-00aa-4124-b380-0c55378fd595"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your natural language SQL query: What is the average price per night for all listings in the database?\n",
            "üîπ Zero-Shot Output:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-ef4ed8c6aa23>:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "<ipython-input-23-ef4ed8c6aa23>:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  return chain.run({\"schema\": schema, \"question\": question})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT AVG(price) AS average_price_per_night\n",
            "FROM listings;\n",
            "```\n",
            "\n",
            "This SQL query calculates the average price per night for all listings in the database by selecting the `price` column and applying the `AVG` function. The result is aliased as `average_price_per_night` for clarity.\n",
            "\n",
            "üîπ Few-Shot Output:\n",
            "    **SQL Query:**\n",
            "    ```sql\n",
            "SELECT AVG(price) AS avg_price_per_night\n",
            "FROM listings;\n",
            "```\n",
            "\n",
            "    This SQL query calculates the average price per night for all listings in the database by using the `AVG()` function on the `price` column. The result is a single row with a single column, `avg_price_per_night`, containing the average price per night for all listings.\n",
            "\n",
            "üîπ Chain-of-Thought Output:\n",
            "### Step 1: Understanding the Request\n",
            "\n",
            "- The key entity involved in the query is the \"listings\" table.\n",
            "- The relationship between tables is that the \"reviews\" table has a foreign key referencing the \"listings\" table.\n",
            "- The necessary SQL operations required are to select the average price per night for all listings.\n",
            "\n",
            "### Step 2: Breaking Down the Query Construction\n",
            "\n",
            "- The base table to query from is the \"listings\" table.\n",
            "- The columns that should be selected are the \"price\" column.\n",
            "- There are no filtering, aggregation, or sorting conditions required.\n",
            "\n",
            "### Step 3: Constructing the SQL Query\n",
            "\n",
            "To calculate the average price per night for all listings, we can use the AVG() function in SQL. Since we are only interested in the \"price\" column, we will select only that column.\n",
            "\n",
            "```sql\n",
            "SELECT AVG(price) AS average_price\n",
            "FROM listings;\n",
            "```\n",
            "\n",
            "This query will return the average price per night for all listings in the database. The AVG() function calculates the average of all values in the specified column, and the AS keyword is used to give an alias to the calculated column, making it easier to read and understand the results.\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "- The AVG() function calculates the average of all values in the \"price\" column.\n",
            "- The SELECT statement specifies the column(s) to be selected.\n",
            "- The FROM clause specifies the table(s) to retrieve data from.\n",
            "- The AS keyword is used to give an alias to the calculated column, making it easier to read and understand the results.\n",
            "\n",
            "üîπ Self-Consistency Output:\n",
            "Here are three different candidate SQL queries to find the average price per night for all listings in the database:\n",
            "\n",
            "**Candidate 1:**\n",
            "```sql\n",
            "SELECT AVG(price) AS average_price\n",
            "FROM listings;\n",
            "```\n",
            "\n",
            "**Candidate 2:**\n",
            "```sql\n",
            "SELECT AVG(l.price) AS average_price\n",
            "FROM listings l;\n",
            "```\n",
            "\n",
            "**Candidate 3:**\n",
            "```sql\n",
            "SELECT AVG(CAST(price AS REAL)) AS average_price\n",
            "FROM listings;\n",
            "```\n",
            "\n",
            "Now, let's analyze the three queries:\n",
            "\n",
            "1.  **Candidate 1:** This query is straightforward and directly calculates the average price from the `price` column. It is efficient and easy to read.\n",
            "\n",
            "2.  **Candidate 2:** This query is similar to Candidate 1 but uses an alias `l` for the `listings` table. It is also efficient and easy to read.\n",
            "\n",
            "3.  **Candidate 3:** This query casts the `price` column to `REAL` before calculating the average. This is necessary because the `AVG` function in SQL requires numeric data types. However, this query might be slightly less efficient than the other two because it involves an additional cast operation.\n",
            "\n",
            "Based on correctness and efficiency, I recommend **Candidate 1**:\n",
            "\n",
            "```sql\n",
            "SELECT AVG(price) AS average_price\n",
            "FROM listings;\n",
            "```\n",
            "\n",
            "This query is simple, efficient, and easy to read. It directly calculates the average price from the `price` column without any additional operations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Little More complex Query**"
      ],
      "metadata": {
        "id": "X1cyqH9PbeOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let the user input their natural language query\n",
        "user_query = input(\"Enter your natural language SQL query: \")\n",
        "\n",
        "# Generate SQL using different prompting techniques\n",
        "print(\"üîπ Zero-Shot Output:\")\n",
        "print(generate_sql(user_query, schema_description, zero_shot_prompt))\n",
        "\n",
        "print(\"\\nüîπ Few-Shot Output:\")\n",
        "print(generate_sql(user_query, schema_description, few_shot_prompt))\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Output:\")\n",
        "print(generate_sql(user_query, schema_description, cot_prompt))\n",
        "\n",
        "print(\"\\nüîπ Self-Consistency Output:\")\n",
        "print(generate_sql(user_query, schema_description, self_consistency_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa9U-9tYYc9p",
        "outputId": "21175624-e1c8-42fc-eb97-1485456bf150"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your natural language SQL query: For each property type, show the total number of listings and the average review score rating.\n",
            "üîπ Zero-Shot Output:\n",
            "```sql\n",
            "SELECT \n",
            "    property_type,\n",
            "    COUNT(*) AS total_listings,\n",
            "    AVG(review_scores_rating) AS average_review_score\n",
            "FROM \n",
            "    listings\n",
            "GROUP BY \n",
            "    property_type\n",
            "ORDER BY \n",
            "    property_type;\n",
            "```\n",
            "\n",
            "This SQL query generates the required output by grouping the listings by property type, counting the total number of listings for each type, and calculating the average review score rating for each type. The results are ordered by property type for easier reference.\n",
            "\n",
            "üîπ Few-Shot Output:\n",
            "  **SQL Query:**\n",
            "  ```sql\n",
            "SELECT \n",
            "  property_type, \n",
            "  COUNT(listing_id) AS total_listings, \n",
            "  AVG(review_scores_rating) AS avg_rating\n",
            "FROM \n",
            "  listings\n",
            "GROUP BY \n",
            "  property_type;\n",
            "```\n",
            "\n",
            "This SQL query will return the total number of listings for each property type and the average review score rating for each property type.\n",
            "\n",
            "üîπ Chain-of-Thought Output:\n",
            "### Step 1: Understanding the Request\n",
            "\n",
            "- Key entities involved: `listings` and `reviews`.\n",
            "- Relationships between tables: `listings` has a foreign key `listing_id` referencing `reviews` (`review_id`).\n",
            "- Necessary SQL operations: `GROUP BY`, `COUNT`, `AVG`.\n",
            "\n",
            "### Step 2: Breaking Down the Query Construction\n",
            "\n",
            "- Base table to query from: `listings`.\n",
            "- Columns to select: `property_type`, `listing_id`.\n",
            "- Filtering, aggregation, or sorting conditions:\n",
            "  - Filter by `property_type`.\n",
            "  - Group by `property_type`.\n",
            "  - Count the number of listings for each `property_type`.\n",
            "  - Calculate the average review score rating for each `property_type`.\n",
            "\n",
            "### Step 3: Constructing the SQL Query\n",
            "\n",
            "```sql\n",
            "SELECT \n",
            "  l.property_type,\n",
            "  COUNT(l.listing_id) AS total_listings,\n",
            "  AVG(r.review_scores_rating) AS avg_review_score\n",
            "FROM \n",
            "  listings l\n",
            "  LEFT JOIN reviews r ON l.listing_id = r.listing_id\n",
            "GROUP BY \n",
            "  l.property_type\n",
            "ORDER BY \n",
            "  total_listings DESC;\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "- We join the `listings` table with the `reviews` table on the `listing_id` column to link each listing with its reviews.\n",
            "- We use a `LEFT JOIN` to include listings without reviews.\n",
            "- We group the results by `property_type`.\n",
            "- We count the number of listings (`total_listings`) for each `property_type`.\n",
            "- We calculate the average review score rating (`avg_review_score`) for each `property_type`.\n",
            "- We order the results by the total number of listings in descending order.\n",
            "\n",
            "This query will provide the total number of listings and the average review score rating for each property type.\n",
            "\n",
            "üîπ Self-Consistency Output:\n",
            "Based on the provided database schema and question, I will generate three different candidate SQL queries.\n",
            "\n",
            "**Candidate 1:**\n",
            "```sql\n",
            "SELECT \n",
            "    property_type, \n",
            "    COUNT(*) AS total_listings, \n",
            "    AVG(review_scores_rating) AS avg_review_score\n",
            "FROM \n",
            "    listings\n",
            "GROUP BY \n",
            "    property_type;\n",
            "```\n",
            "\n",
            "**Candidate 2:**\n",
            "```sql\n",
            "SELECT \n",
            "    l.property_type, \n",
            "    COUNT(l.listing_id) AS total_listings, \n",
            "    AVG(r.review_scores_rating) AS avg_review_score\n",
            "FROM \n",
            "    listings l\n",
            "JOIN \n",
            "    reviews r ON l.listing_id = r.listing_id\n",
            "GROUP BY \n",
            "    l.property_type;\n",
            "```\n",
            "\n",
            "**Candidate 3:**\n",
            "```sql\n",
            "SELECT \n",
            "    property_type, \n",
            "    COUNT(*) AS total_listings, \n",
            "    AVG(review_scores_rating) AS avg_review_score\n",
            "FROM \n",
            "    listings l\n",
            "JOIN \n",
            "    reviews r ON l.listing_id = r.listing_id\n",
            "GROUP BY \n",
            "    l.property_type;\n",
            "```\n",
            "\n",
            "Now, let's analyze the three queries and select the best one based on correctness and efficiency.\n",
            "\n",
            "**Analysis:**\n",
            "\n",
            "1.  **Correctness:** All three queries are correct in terms of syntax and logic. They join the `listings` and `reviews` tables based on the `listing_id` column and group the results by the `property_type` column. However, Candidate 2 is slightly more accurate because it explicitly joins the tables, which can help prevent errors if the schema changes in the future.\n",
            "2.  **Efficiency:** The efficiency of the queries can be evaluated based on the number of joins, the use of indexes, and the aggregation operations. Candidate 1 is the most efficient because it uses a single table (`listings`) and a simple `GROUP BY` clause. Candidate 2 and Candidate 3 both use a join, which can slow down the query. However, Candidate 2 uses a `JOIN` with an `ON` clause, which is more efficient than a correlated subquery used in Candidate 3.\n",
            "3.  **Indexing:** To optimize the query further, it's essential to create indexes on the columns used in the `WHERE`, `JOIN`, and `GROUP BY` clauses. Specifically, indexes on the `listing_id` column in the `listings` table and the `listing_id` column in the `reviews` table can improve the query performance.\n",
            "\n",
            "**Final Selected SQL Query:**\n",
            "\n",
            "Based on the analysis, the final selected SQL query is:\n",
            "\n",
            "```sql\n",
            "SELECT \n",
            "    l.property_type, \n",
            "    COUNT(l.listing_id) AS total_listings, \n",
            "    AVG(r.review_scores_rating) AS avg_review_score\n",
            "FROM \n",
            "    listings l\n",
            "JOIN \n",
            "    reviews r ON l.listing_id = r.listing_id\n",
            "GROUP BY \n",
            "    l.property_type;\n",
            "```\n",
            "\n",
            "This query is accurate, efficient, and well-structured. It joins the `listings` and `reviews` tables based on the `listing_id` column and groups the results by the `property_type` column. The use of a `JOIN` with an `ON` clause makes the query more efficient than a correlated subquery. Additionally, creating indexes on the `listing_id` columns in both tables can further improve the query performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Generated SQL Queries\n"
      ],
      "metadata": {
        "id": "ulOD4c63Y_Rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute the Generated SQL Query"
      ],
      "metadata": {
        "id": "QDTwnPeSZrBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY2Ym4HCanLO",
        "outputId": "ced3b4ec-5757-461a-aec8-4ee3dc0ce2d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "from tabulate import tabulate\n",
        "\n",
        "def run_sql_query(query):\n",
        "    try:\n",
        "        # Connect to your PostgreSQL database\n",
        "        conn = psycopg2.connect(\n",
        "            dbname=\"airbnb\",\n",
        "            user=\"postgres\",\n",
        "            password=\"006563\",  # Replace with your actual password\n",
        "            host=\"localhost\"\n",
        "        )\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Execute the query\n",
        "        cursor.execute(query)\n",
        "        results = cursor.fetchall()\n",
        "\n",
        "        # Fetch column names\n",
        "        colnames = [desc[0] for desc in cursor.description]\n",
        "\n",
        "        # Print the results in a tabular format similar to SQL output\n",
        "        print(tabulate(results, headers=colnames, tablefmt=\"psql\"))\n",
        "\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error executing query:\", e)\n",
        "        return None\n",
        "\n",
        "# Example: Run a generated query\n",
        "generated_query = \"SELECT AVG(price) AS average_price FROM listings;\"\n",
        "results = run_sql_query(generated_query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miaweGQJaq1k",
        "outputId": "45f46bad-c3cf-45d5-87c1-d2640d46973d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|   average_price |\n",
            "|-----------------|\n",
            "|         608.793 |\n",
            "+-----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify Correctness"
      ],
      "metadata": {
        "id": "xmRWI3flbJcK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tk5zcosCbOM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}